import os
import time
import tracemalloc

from patching import patchers


def list_generators() -> list[str]:
    """
    List all generators for which there are levels generated by the previous pipeline stage.
    :return: List of paths to all generators
    """
    base_path: str = os.path.join(os.path.curdir, "data")
    return os.listdir(base_path)


def benchmark(fn: callable):
    """
    Decorator to measure the runtime of a function.
    :param fn: Function to measure
    :return: Function result and runtime
    """
    def wrapper(*args, **kwargs):
        tracemalloc.start()

        start = time.time()
        result = fn(*args, **kwargs)
        end = time.time()

        _, peak = tracemalloc.get_traced_memory()

        tracemalloc.stop()

        return result, end - start, peak
    return wrapper


def save_metric_to_file(generator_dir: str, data: dict, name: str):
    """
    Save a metric as a csv file
    :param generator_dir: Path to the generator directory
    :param data: Metric data
    :param name: Name of the metric
    :return: None
    """
    with open(os.path.join(os.path.curdir, "data", generator_dir, name + ".csv"), "w") as f:
        f.write("level,patcher,value\n")
        for level, patches in data.items():
            for patcher, value in patches.items():
                f.write(f"{level},{patcher},{value}\n")


def test_levels(generator_dir: str):
    """
    Test all levels generated by the previous pipeline stage.
    :param generator_dir: Path to the generator directory
    :return: None
    """
    level_files: list[str] = os.listdir(os.path.join(os.path.curdir, "data", generator_dir))

    # level_name -> (patcher_name -> (metric_name -> metric_value))
    runtimes = {}
    memory_usage = {}

    for level_file in level_files:
        # Ignore non-level files
        if not level_file.endswith(".txt"):
            continue

        level_path: str = os.path.join(os.path.curdir, "data", generator_dir, level_file)

        # Read level line by line
        level: list[str] = []
        with open(level_path, "r") as f:
            for line in f:
                level.append(line.rstrip())

        # First line is the progress the agent made, read and remove it
        progress: str = level[0]
        level = level[1:]

        # Level height is the number of lines in the level
        level_height: int = len(level)
        # Level width is the length of the first line
        level_width: int = len(level[0])

        progress_blocks: int = int(float(level_width) * float(progress))

        broken_range = (
            (max(progress_blocks - 5, 0), min(progress_blocks + 5, level_width)),
            (0, level_height)
        )

        # Iterate available patchers
        for patcher_name, patcher in patchers.items():
            print(f"Repairing {level_file} with {patcher_name}...")

            @benchmark
            def patcher_fn():
                return patcher.patch(level, broken_range)

            patched_level_section, runtime, peak_mem = patcher_fn()

            if level_file not in runtimes:
                runtimes[level_file] = {}

            runtimes[level_file][patcher_name] = runtime

            if level_file not in memory_usage:
                memory_usage[level_file] = {}

            memory_usage[level_file][patcher_name] = peak_mem

    save_metric_to_file(generator_dir, runtimes, "Runtime")
    save_metric_to_file(generator_dir, memory_usage, "Memory")


generator_paths = list_generators()
for generator_path in generator_paths:
    test_levels(generator_path)
